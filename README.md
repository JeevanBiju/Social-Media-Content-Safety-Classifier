# Judge the Feed: Safe, Unsafe, or Neutral?

## ğŸ“Œ Overview
A social media content moderation tool that classifies posts based on toxicity and emotional tone to ensure child-safe content.

## ğŸ“ Project Structure
- `classify_feed.py` â€“ Main content classification script
- `moderated_feed.csv` â€“ Output file with labels and reasons
- `report_summary.json` â€“ JSON report with summary stats and examples
- `requirements.txt` â€“ List of dependencies
- `README.md` â€“ Project documentation
